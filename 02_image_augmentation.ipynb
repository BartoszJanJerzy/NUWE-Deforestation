{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from utils.augmentation import AugmentationPipeline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "    'data': os.path.join(os.getcwd(), 'data'),\n",
    "    'train': os.path.join(os.getcwd(), 'data', 'train'),\n",
    "    'test': os.path.join(os.getcwd(), 'data', 'test')\n",
    "}\n",
    "\n",
    "def load_datafile_path(file: str) -> str: return os.path.join(PATHS['data'], file)\n",
    "def load_train_image_path(file: str) -> str: return os.path.join(PATHS['train'], file)\n",
    "def load_test_image_path(file: str) -> str: return os.path.join(PATHS['test'], file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_feather(load_datafile_path('train.ftr'))\n",
    "train_info = train_info[train_info['year'] >= 2012]\n",
    "train_info = (\n",
    "    train_info\n",
    "    .sample(len(train_info))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "images_paths = train_info['example_path']\n",
    "images_names = [p.split('/')[-1] for p in images_paths]\n",
    "images = [cv2.imread(load_train_image_path(images_names[i])) for i in tqdm(range(len(images_names)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentator = AugmentationPipeline(332, 332)\n",
    "images_aug = augmentator.load_augmented_images(images)\n",
    "images_aug = images_aug + augmentator.load_augmented_images(images)\n",
    "images_aug = images_aug + augmentator.load_augmented_images(images)\n",
    "\n",
    "for img in images_aug:\n",
    "    assert img.shape == (332, 332, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'images': images_aug,\n",
    "    'labels': train_info['label'].to_list() * 9\n",
    "}\n",
    "\n",
    "with open(load_datafile_path('augmented_data'), 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df334b9baf988a808dd302c0f32b1b4e4d2454b9dbc8352ea80b8ff7878e3aeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
